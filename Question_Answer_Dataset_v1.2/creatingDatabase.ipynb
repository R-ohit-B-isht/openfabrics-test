{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from tqdm import tqdm\n",
    "import docx\n",
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = \"/workspace/openfabrics-test/Question_Answer_Dataset_v1.2/S08/data/set1\"\n",
    "text_chunks = []\n",
    "for f_name in os.listdir(docs_path):\n",
    "  doc_path = os.path.join(docs_path, f_name)\n",
    "  doc = docx.Document(doc_path)\n",
    "  for para in doc.paragraphs:\n",
    "    text_chunks.append(para.text)\n",
    "\n",
    "# remove all chunks shorter than 10 words and strip the rest\n",
    "text_chunks = [string.strip().strip('\\n') for string in text_chunks if len(string.split()) >= 5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *generate embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_with_embeddigns = []\n",
    "for chunk in tqdm(text_chunks):\n",
    "  embedding = get_embedding(chunk, engine='text-embedding-ada-002')\n",
    "  chunks_with_embeddigns.append({\"text\": chunk, \"embedding\": embedding})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=\"fdb1d596-e03e-4928-ae15-b1f9ba1fe7d6\",\n",
    "    environment=\"asia-southeast1-gcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or connect to index\n",
    "index_name = \"ScineceBot-2023\"\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=1536)\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # process everything in batches of 64\n",
    "for i in tqdm(range(0, len(chunks_with_embeddigns), batch_size)):\n",
    "    data_batch = chunks_with_embeddigns.iloc[i: i+batch_size]\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(chunks_with_embeddigns))\n",
    "    # get batch meta\n",
    "    text_batch = [item['text'] for item in data_batch]\n",
    "    # get ids\n",
    "    ids_batch = [str(n) for n in range(i, i_end)]\n",
    "    # get embeddings\n",
    "    embeds = [item['embedding'] for item in data_batch]\n",
    "    # prep metadata and upsert batch\n",
    "    meta = [{'text': text_batch} for text_batch in zip(text_batch)] # you can add more fields here\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
